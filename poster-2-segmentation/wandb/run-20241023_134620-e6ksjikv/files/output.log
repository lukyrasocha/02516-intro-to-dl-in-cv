Traceback (most recent call last):
  File "/zhome/26/8/209207/02516-intro-to-dl-in-cv/poster-2-segmentation/main.py", line 163, in <module>
    train_model(UNetModel, drive_train_loader, drive_val_loader, loss_fn, optimizer, wandb_config=config, num_epochs= MAX_EPOCHS, device=DEVICE)
  File "/zhome/26/8/209207/02516-intro-to-dl-in-cv/poster-2-segmentation/models/train.py", line 24, in train_model
    outputs = model(images)
  File "/zhome/26/8/209207/venv/project2_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/zhome/26/8/209207/venv/project2_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/zhome/26/8/209207/02516-intro-to-dl-in-cv/poster-2-segmentation/models/models.py", line 132, in forward
    up_1 = self.up_convolution_1(b, down_4)
  File "/zhome/26/8/209207/venv/project2_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/zhome/26/8/209207/venv/project2_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/zhome/26/8/209207/02516-intro-to-dl-in-cv/poster-2-segmentation/models/models.py", line 102, in forward
    return self.conv(x)
  File "/zhome/26/8/209207/venv/project2_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/zhome/26/8/209207/venv/project2_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/zhome/26/8/209207/02516-intro-to-dl-in-cv/poster-2-segmentation/models/models.py", line 77, in forward
    return self.conv_op(x)
  File "/zhome/26/8/209207/venv/project2_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/zhome/26/8/209207/venv/project2_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/zhome/26/8/209207/venv/project2_venv/lib64/python3.9/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/zhome/26/8/209207/venv/project2_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/zhome/26/8/209207/venv/project2_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/zhome/26/8/209207/venv/project2_venv/lib64/python3.9/site-packages/torch/nn/modules/conv.py", line 554, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/zhome/26/8/209207/venv/project2_venv/lib64/python3.9/site-packages/torch/nn/modules/conv.py", line 549, in _conv_forward
    return F.conv2d(
RuntimeError: Given groups=1, weight of size [512, 1024, 3, 3], expected input[3, 1536, 64, 64] to have 1024 channels, but got 1536 channels instead
